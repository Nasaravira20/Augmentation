{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/mw/.cache/kagglehub/datasets/uciml/adult-census-income/versions/3\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"uciml/adult-census-income\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x73f2dc4a41d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'education.num',\n",
      "       'marital.status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital.gain', 'capital.loss', 'hours.per.week', 'native.country',\n",
      "       'income'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "0   90         ?   77053       HS-grad              9        Widowed   \n",
       "1   82   Private  132870       HS-grad              9        Widowed   \n",
       "2   66         ?  186061  Some-college             10        Widowed   \n",
       "3   54   Private  140359       7th-8th              4       Divorced   \n",
       "4   41   Private  264663  Some-college             10      Separated   \n",
       "\n",
       "          occupation   relationship   race     sex  capital.gain  \\\n",
       "0                  ?  Not-in-family  White  Female             0   \n",
       "1    Exec-managerial  Not-in-family  White  Female             0   \n",
       "2                  ?      Unmarried  Black  Female             0   \n",
       "3  Machine-op-inspct      Unmarried  White  Female             0   \n",
       "4     Prof-specialty      Own-child  White  Female             0   \n",
       "\n",
       "   capital.loss  hours.per.week native.country income  \n",
       "0          4356              40  United-States  <=50K  \n",
       "1          4356              18  United-States  <=50K  \n",
       "2          4356              40  United-States  <=50K  \n",
       "3          3900              40  United-States  <=50K  \n",
       "4          3900              40  United-States  <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Load and clean the data\n",
    "data = pd.read_csv(\"/home/mw/.cache/kagglehub/datasets/uciml/adult-census-income/versions/3/adult.csv\")\n",
    "data = data.dropna()\n",
    "print(data.columns)\n",
    "data.columns = data.columns.str.strip()\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['workclass', 'education', 'marital.status', 'occupation',\n",
      "       'relationship', 'race', 'sex', 'native.country', 'income'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_?</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>native.country_Portugal</th>\n",
       "      <th>native.country_Puerto-Rico</th>\n",
       "      <th>native.country_Scotland</th>\n",
       "      <th>native.country_South</th>\n",
       "      <th>native.country_Taiwan</th>\n",
       "      <th>native.country_Thailand</th>\n",
       "      <th>native.country_Trinadad&amp;Tobago</th>\n",
       "      <th>native.country_United-States</th>\n",
       "      <th>native.country_Vietnam</th>\n",
       "      <th>native.country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.043987</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.890411</td>\n",
       "      <td>0.081896</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.173469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.671233</td>\n",
       "      <td>0.118021</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.506849</td>\n",
       "      <td>0.086982</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.895317</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.328767</td>\n",
       "      <td>0.171404</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.895317</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.202298</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.166404</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>0.315068</td>\n",
       "      <td>0.096500</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>0.561644</td>\n",
       "      <td>0.094827</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.128499</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    fnlwgt  education.num  sex  capital.gain  capital.loss  \\\n",
       "0      1.000000  0.043987       0.533333  0.0           0.0      1.000000   \n",
       "1      0.890411  0.081896       0.533333  0.0           0.0      1.000000   \n",
       "2      0.671233  0.118021       0.600000  0.0           0.0      1.000000   \n",
       "3      0.506849  0.086982       0.200000  0.0           0.0      0.895317   \n",
       "4      0.328767  0.171404       0.600000  0.0           0.0      0.895317   \n",
       "...         ...       ...            ...  ...           ...           ...   \n",
       "32556  0.068493  0.202298       0.600000  1.0           0.0      0.000000   \n",
       "32557  0.136986  0.166404       0.733333  0.0           0.0      0.000000   \n",
       "32558  0.315068  0.096500       0.533333  1.0           0.0      0.000000   \n",
       "32559  0.561644  0.094827       0.533333  0.0           0.0      0.000000   \n",
       "32560  0.068493  0.128499       0.533333  1.0           0.0      0.000000   \n",
       "\n",
       "       hours.per.week  income  workclass_?  workclass_Federal-gov  ...  \\\n",
       "0            0.397959     0.0          1.0                    0.0  ...   \n",
       "1            0.173469     0.0          0.0                    0.0  ...   \n",
       "2            0.397959     0.0          1.0                    0.0  ...   \n",
       "3            0.397959     0.0          0.0                    0.0  ...   \n",
       "4            0.397959     0.0          0.0                    0.0  ...   \n",
       "...               ...     ...          ...                    ...  ...   \n",
       "32556        0.397959     0.0          0.0                    0.0  ...   \n",
       "32557        0.377551     0.0          0.0                    0.0  ...   \n",
       "32558        0.397959     1.0          0.0                    0.0  ...   \n",
       "32559        0.397959     0.0          0.0                    0.0  ...   \n",
       "32560        0.193878     0.0          0.0                    0.0  ...   \n",
       "\n",
       "       native.country_Portugal  native.country_Puerto-Rico  \\\n",
       "0                          0.0                         0.0   \n",
       "1                          0.0                         0.0   \n",
       "2                          0.0                         0.0   \n",
       "3                          0.0                         0.0   \n",
       "4                          0.0                         0.0   \n",
       "...                        ...                         ...   \n",
       "32556                      0.0                         0.0   \n",
       "32557                      0.0                         0.0   \n",
       "32558                      0.0                         0.0   \n",
       "32559                      0.0                         0.0   \n",
       "32560                      0.0                         0.0   \n",
       "\n",
       "       native.country_Scotland  native.country_South  native.country_Taiwan  \\\n",
       "0                          0.0                   0.0                    0.0   \n",
       "1                          0.0                   0.0                    0.0   \n",
       "2                          0.0                   0.0                    0.0   \n",
       "3                          0.0                   0.0                    0.0   \n",
       "4                          0.0                   0.0                    0.0   \n",
       "...                        ...                   ...                    ...   \n",
       "32556                      0.0                   0.0                    0.0   \n",
       "32557                      0.0                   0.0                    0.0   \n",
       "32558                      0.0                   0.0                    0.0   \n",
       "32559                      0.0                   0.0                    0.0   \n",
       "32560                      0.0                   0.0                    0.0   \n",
       "\n",
       "       native.country_Thailand  native.country_Trinadad&Tobago  \\\n",
       "0                          0.0                             0.0   \n",
       "1                          0.0                             0.0   \n",
       "2                          0.0                             0.0   \n",
       "3                          0.0                             0.0   \n",
       "4                          0.0                             0.0   \n",
       "...                        ...                             ...   \n",
       "32556                      0.0                             0.0   \n",
       "32557                      0.0                             0.0   \n",
       "32558                      0.0                             0.0   \n",
       "32559                      0.0                             0.0   \n",
       "32560                      0.0                             0.0   \n",
       "\n",
       "       native.country_United-States  native.country_Vietnam  \\\n",
       "0                               1.0                     0.0   \n",
       "1                               1.0                     0.0   \n",
       "2                               1.0                     0.0   \n",
       "3                               1.0                     0.0   \n",
       "4                               1.0                     0.0   \n",
       "...                             ...                     ...   \n",
       "32556                           1.0                     0.0   \n",
       "32557                           1.0                     0.0   \n",
       "32558                           1.0                     0.0   \n",
       "32559                           1.0                     0.0   \n",
       "32560                           1.0                     0.0   \n",
       "\n",
       "       native.country_Yugoslavia  \n",
       "0                            0.0  \n",
       "1                            0.0  \n",
       "2                            0.0  \n",
       "3                            0.0  \n",
       "4                            0.0  \n",
       "...                          ...  \n",
       "32556                        0.0  \n",
       "32557                        0.0  \n",
       "32558                        0.0  \n",
       "32559                        0.0  \n",
       "32560                        0.0  \n",
       "\n",
       "[32561 rows x 108 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "print(categorical_columns)\n",
    "\n",
    "# Apply one-hot encoding for categorical columns\n",
    "for col in categorical_columns:\n",
    "    if data[col].nunique() <= 2:\n",
    "        data[col] = LabelEncoder().fit_transform(data[col])\n",
    "    else:\n",
    "        one_hot = pd.get_dummies(data[col], prefix=col)\n",
    "        data = pd.concat([data.drop(col, axis=1), one_hot], axis=1)\n",
    "\n",
    "boolean_columns = data.select_dtypes(include='bool').columns\n",
    "data[boolean_columns] = data[boolean_columns].astype(int)           \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor shape: torch.Size([26048, 107])\n",
      "y_train_tensor shape: torch.Size([26048])\n",
      "X_val_tensor shape: torch.Size([6513, 107])\n",
      "y_val_tensor shape: torch.Size([6513])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "target_column = 'income'\n",
    "X = data.drop(columns=target_column)\n",
    "y = data[target_column]\n",
    "\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors after converting to NumPy array\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.long)\n",
    "0\n",
    "# Display the tensor shapes to confirm\n",
    "print(\"X_train_tensor shape:\", X_train_tensor.shape)\n",
    "print(\"y_train_tensor shape:\", y_train_tensor.shape)\n",
    "print(\"X_val_tensor shape:\", X_val_tensor.shape)\n",
    "print(\"y_val_tensor shape:\", y_val_tensor.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, condition_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim + condition_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc_mean = nn.Linear(128, latent_dim)\n",
    "        self.fc_log_var = nn.Linear(128, latent_dim)\n",
    "        self.LeakyRelu = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x, condition):\n",
    "        # print(\"x \", x.shape)\n",
    "        x = torch.cat([x, condition], dim=-1)  # Concatenate the condition to the input\n",
    "        # print(\"concat :\",x.shape )\n",
    "        x = self.LeakyRelu(self.fc1(x))\n",
    "        x = self.dropout(self.LeakyRelu(self.fc2(x)))\n",
    "        x = self.LeakyRelu(self.fc3(x))\n",
    "        mean = self.fc_mean(x)\n",
    "        log_var = self.fc_log_var(x)\n",
    "        return mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim, condition_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(latent_dim + condition_dim, 128)  # Latent + condition\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 512)\n",
    "        self.fc_output = nn.Linear(512, output_dim)\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, z, condition):\n",
    "        z = torch.cat([z, condition], dim=-1)  # Concatenate the condition to the latent\n",
    "        z = self.lrelu(self.fc1(z))\n",
    "        z = self.dropout(self.lrelu(self.fc2(z)))\n",
    "        z = self.lrelu(self.fc3(z))\n",
    "        reconstructed_x = self.sigmoid(self.fc_output(z))\n",
    "        return reconstructed_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, condition_dim,beta = 0.1):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, latent_dim, condition_dim)\n",
    "        self.decoder = Decoder(latent_dim, input_dim, condition_dim)\n",
    "        self.beta = nn.Parameter(torch.tensor(0.1))\n",
    "\n",
    "    def forward(self, x, condition):\n",
    "        mu, log_var = self.encoder(x, condition)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        reconstructed_x = self.decoder(z, condition)\n",
    "        return reconstructed_x, mu, log_var\n",
    "\n",
    "    @staticmethod\n",
    "    def reparameterize(mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26048, 1])\n",
      "torch.Size([26048, 107])\n"
     ]
    }
   ],
   "source": [
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long).unsqueeze(1)  # Add an extra dimension\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.long).unsqueeze(1)  \n",
    "print(y_train_tensor.shape)\n",
    "print(X_train_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_tensor = torch.tensor(scaler.fit_transform(X_train_tensor), dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(scaler.transform(X_val_tensor), dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:02<03:56,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 182.1144, Val Loss: 18.3167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:04<03:27,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Train Loss: 38.4504, Val Loss: 11.0379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:06<03:10,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Train Loss: 34.8166, Val Loss: 9.3135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:07<03:02,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Train Loss: 33.7154, Val Loss: 8.6304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:09<02:55,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Train Loss: 33.3448, Val Loss: 8.3658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:11<02:51,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Train Loss: 33.2512, Val Loss: 8.2918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:13<02:47,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Train Loss: 33.2277, Val Loss: 8.2687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:14<02:43,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Train Loss: 33.2121, Val Loss: 8.2606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:16<02:40,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Train Loss: 33.1998, Val Loss: 8.2527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:18<02:38,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Train Loss: 33.1622, Val Loss: 8.2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:20<02:37,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Train Loss: 32.9969, Val Loss: 8.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:21<02:34,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Train Loss: 32.8255, Val Loss: 8.1547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:23<02:32,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Train Loss: 32.7970, Val Loss: 8.1512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:25<02:31,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Train Loss: 32.7759, Val Loss: 8.1483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:27<02:28,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100], Train Loss: 32.7848, Val Loss: 8.1457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:28<02:27,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100], Train Loss: 32.7735, Val Loss: 8.1439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [00:30<02:25,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Train Loss: 32.7784, Val Loss: 8.1423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [00:32<02:23,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100], Train Loss: 32.7613, Val Loss: 8.1411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [00:34<02:21,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100], Train Loss: 32.7604, Val Loss: 8.1405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [00:35<02:20,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Train Loss: 32.7654, Val Loss: 8.1384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:37<02:18,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100], Train Loss: 32.7545, Val Loss: 8.1382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [00:39<02:16,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100], Train Loss: 32.7609, Val Loss: 8.1372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [00:41<02:14,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100], Train Loss: 32.7518, Val Loss: 8.1359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [00:42<02:12,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100], Train Loss: 32.7508, Val Loss: 8.1353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [00:44<02:09,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100], Train Loss: 32.7674, Val Loss: 8.1341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [00:46<02:07,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100], Train Loss: 32.7435, Val Loss: 8.1340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [00:47<02:05,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100], Train Loss: 32.7570, Val Loss: 8.1330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [00:49<02:05,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100], Train Loss: 32.7488, Val Loss: 8.1323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [00:51<02:06,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100], Train Loss: 32.7683, Val Loss: 8.1443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [00:53<02:02,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100], Train Loss: 32.7566, Val Loss: 8.1315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [00:55<02:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100], Train Loss: 32.7446, Val Loss: 8.1303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [00:56<02:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100], Train Loss: 32.7541, Val Loss: 8.1299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [00:58<01:58,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100], Train Loss: 32.7405, Val Loss: 8.1295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [01:00<01:57,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100], Train Loss: 32.7465, Val Loss: 8.1295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [01:02<01:54,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100], Train Loss: 32.7500, Val Loss: 8.1296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [01:03<01:52,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100], Train Loss: 32.7505, Val Loss: 8.1286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [01:05<01:48,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100], Train Loss: 32.7391, Val Loss: 8.1292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [01:07<01:46,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100], Train Loss: 32.7446, Val Loss: 8.1276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [01:09<01:46,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100], Train Loss: 32.7479, Val Loss: 8.1279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [01:10<01:45,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100], Train Loss: 32.7504, Val Loss: 8.1275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [01:12<01:42,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100], Train Loss: 32.7388, Val Loss: 8.1273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [01:14<01:41,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100], Train Loss: 32.7509, Val Loss: 8.1270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [01:16<01:38,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100], Train Loss: 32.7458, Val Loss: 8.1273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [01:17<01:36,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100], Train Loss: 32.7352, Val Loss: 8.1274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [01:19<01:35,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/100], Train Loss: 32.7376, Val Loss: 8.1269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [01:21<01:33,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/100], Train Loss: 32.7443, Val Loss: 8.1269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [01:22<01:31,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/100], Train Loss: 32.7460, Val Loss: 8.1267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [01:24<01:28,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/100], Train Loss: 32.7441, Val Loss: 8.1271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [01:26<01:26,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100], Train Loss: 32.7454, Val Loss: 8.1271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [01:27<01:24,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100], Train Loss: 32.7405, Val Loss: 8.1264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [01:29<01:21,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100], Train Loss: 32.7469, Val Loss: 8.1266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [01:31<01:19,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/100], Train Loss: 32.7507, Val Loss: 8.1264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [01:32<01:17,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/100], Train Loss: 32.7399, Val Loss: 8.1268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [01:34<01:23,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/100], Train Loss: 32.7438, Val Loss: 8.1264\n",
      "Early stopping triggered due to no improvement in validation loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `features_tensor` and `target_tensor` are prepared and available\n",
    "condition_dim = y_train_tensor.shape[1]  # Example: number of classes or other categorical input\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "latent_dim = 100\n",
    "beta = 0.1\n",
    "\n",
    "# Define the VAE model (ensure that your model can handle `condition_dim` as input)\n",
    "vae = VAE(input_dim, latent_dim, condition_dim)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vae.to(device)\n",
    "\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "reconstruction_loss_fn = nn.SmoothL1Loss(reduction='mean')\n",
    "\n",
    "# Define the VAE loss function\n",
    "def vae_loss(reconstructed_x, x, mu, log_var, beta=1.0):\n",
    "    reconstruction_loss = reconstruction_loss_fn(reconstructed_x, x)\n",
    "    kl_divergence = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    kl_divergence = torch.clamp(kl_divergence, min=0)  # Avoid invalid values\n",
    "    return reconstruction_loss + beta * kl_divergence  # Apply beta scaling\n",
    "\n",
    "# Convert to TensorDataset\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "patience = 10  # Number of epochs without improvement before stopping\n",
    "best_loss = float('inf')\n",
    "epochs_without_improvement = 0 \n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    # Training phase\n",
    "    vae.train()\n",
    "    epoch_train_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, conditions = batch\n",
    "        features = features.to(device)\n",
    "        conditions = conditions.to(device)\n",
    "        reconstructed_x, mu, log_var = vae(features, conditions)\n",
    "\n",
    "        loss = vae_loss(reconstructed_x, features, mu, log_var, beta)\n",
    "        if torch.isnan(loss) or torch.isinf(loss):\n",
    "            print(\"NaN/Inf detected in loss. Skipping this batch.\")\n",
    "            continue\n",
    "\n",
    "        epoch_train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(vae.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    if epoch_train_loss < best_loss:\n",
    "        best_loss = epoch_train_loss\n",
    "        epochs_without_improvement = 0  # Reset counter\n",
    "        # Save model checkpoint when there's an improvement\n",
    "        torch.save(vae.state_dict(), \"best_vae_lrelu_model.pth\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    # print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_train_loss:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    vae.eval()\n",
    "    epoch_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            features, conditions = batch\n",
    "            features = features.to(device)\n",
    "            conditions = conditions.to(device)\n",
    "            reconstructed_x, mu, log_var = vae(features, conditions)\n",
    "\n",
    "            loss = vae_loss(reconstructed_x, features, mu, log_var)\n",
    "            epoch_val_loss += loss.item()\n",
    "\n",
    "    val_losses.append(epoch_val_loss)\n",
    "\n",
    "    tqdm.write(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping condition\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(\"Early stopping triggered due to no improvement in validation loss.\")\n",
    "        break\n",
    "\n",
    "# Plotting training and validation losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss', marker='o')\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss', marker='x')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9999616093366094\n",
      "Validation Accuracy: 0.8113004759711346\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Train the Decision Tree Classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# 2. Make Predictions\n",
    "y_train_pred = dt.predict(X_train)\n",
    "y_val_pred = dt.predict(X_val)\n",
    "\n",
    "# 3. Calculate Accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Display the results\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8514281326781327\n",
      "Validation Accuracy: 0.8481498541378781\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Train the Logistic Regression Model\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# 2. Make Predictions\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_val_pred = lr.predict(X_val)\n",
    "\n",
    "# 3. Calculate Accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Display the results\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2992/585296845.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  vae.load_state_dict(torch.load(\"best_vae_lrelu_model.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Encoder(\n",
       "    (fc1): Linear(in_features=108, out_features=512, bias=True)\n",
       "    (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (fc_mean): Linear(in_features=128, out_features=100, bias=True)\n",
       "    (fc_log_var): Linear(in_features=128, out_features=100, bias=True)\n",
       "    (LeakyRelu): LeakyReLU(negative_slope=0.01)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (fc1): Linear(in_features=101, out_features=128, bias=True)\n",
       "    (fc2): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (fc3): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (fc_output): Linear(in_features=512, out_features=107, bias=True)\n",
       "    (lrelu): LeakyReLU(negative_slope=0.01)\n",
       "    (sigmoid): Sigmoid()\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Reinitialize the VAE with the same architecture as used during training\n",
    "vae = VAE(input_dim, latent_dim, condition_dim)  # Ensure these dimensions match your training setup\n",
    "vae.load_state_dict(torch.load(\"best_vae_lrelu_model.pth\"))\n",
    "vae.eval()  # Set the model to evaluation mode\n",
    "vae.to(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 100])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Generate synthetic dataconditions = torch.tensor(condition_column, dtype=torch.long).to(device)  # Use actual conditions\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Pass through the decoder (vae.decoder should be defined in your model)\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     generated_data \u001b[38;5;241m=\u001b[39m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconditions\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Assuming no condition for simplicity; modify if conditional\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Convert generated data to CPU and numpy for compatibility with scikit-learn\u001b[39;00m\n\u001b[1;32m     28\u001b[0m generated_data_np \u001b[38;5;241m=\u001b[39m generated_data\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/miniconda3/envs/sih/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sih/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, z, condition)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, z, condition):\n\u001b[0;32m---> 14\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Concatenate the condition to the latent\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(z))\n\u001b[1;32m     16\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(z)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you already have the VAE model loaded and the latent_dim, condition_dim, and device defined\n",
    "\n",
    "# Number of samples to generate\n",
    "num_samples = 1000\n",
    "# latent_dim = 20  # Adjust based on your model's latent space\n",
    "# condition_dim = 10  # Number of classes, adjust accordingly\n",
    "\n",
    "# Sample from a standard normal distribution (mean=0, std=1) in the latent space\n",
    "z = torch.randn(num_samples, latent_dim).to(device)\n",
    "print(z.shape)\n",
    "# Generate random class labels (conditions)\n",
    "# conditions = torch.randint(0, condition_dim, (num_samples,)).to(device)  # Random class labels4\n",
    "condition_column = data['income'].values  # Replace with your actual condition column\n",
    "conditions = torch.tensor(condition_column, dtype=torch.long).to(device)  # Use actual conditions\n",
    "conditions_onehot = torch.nn.functional.one_hot(conditions, num_classes=condition_dim).float()  # One-hot encode\n",
    "\n",
    "# Generate synthetic dataconditions = torch.tensor(condition_column, dtype=torch.long).to(device)  # Use actual conditions\n",
    "with torch.no_grad():\n",
    "    # Pass through the decoder (vae.decoder should be defined in your model)\n",
    "    generated_data = vae.decoder(z,conditions)  # Assuming no condition for simplicity; modify if conditional\n",
    "\n",
    "# Convert generated data to CPU and numpy for compatibility with scikit-learn\n",
    "generated_data_np = generated_data.cpu().numpy()\n",
    "conditions_np = conditions_onehot.cpu().numpy()\n",
    "\n",
    "# Combine the generated data with conditions to form the feature matrix\n",
    "X_generated = torch.cat((generated_data, conditions_onehot), dim=1).cpu().numpy()\n",
    "\n",
    "# Assuming you have labels for the generated data or generate some dummy labels\n",
    "y_generated = torch.randint(0, 2, (num_samples,)).cpu().numpy()  # Dummy binary labels for illustration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_generated, y_generated, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate the Decision Tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the Decision Tree on the generated data\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = dt.predict(X_val)\n",
    "\n",
    "# Evaluate accuracy\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sih",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
