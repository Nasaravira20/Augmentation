{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] | Loss: nan\n",
      "Epoch [2/50] | Loss: nan\n",
      "Epoch [3/50] | Loss: nan\n",
      "Epoch [4/50] | Loss: nan\n",
      "Epoch [5/50] | Loss: nan\n",
      "Epoch [6/50] | Loss: nan\n",
      "Epoch [7/50] | Loss: nan\n",
      "Epoch [8/50] | Loss: nan\n",
      "Epoch [9/50] | Loss: nan\n",
      "Epoch [10/50] | Loss: nan\n",
      "Epoch [11/50] | Loss: nan\n",
      "Epoch [12/50] | Loss: nan\n",
      "Epoch [13/50] | Loss: nan\n",
      "Epoch [14/50] | Loss: nan\n",
      "Epoch [15/50] | Loss: nan\n",
      "Epoch [16/50] | Loss: nan\n",
      "Epoch [17/50] | Loss: nan\n",
      "Epoch [18/50] | Loss: nan\n",
      "Epoch [19/50] | Loss: nan\n",
      "Epoch [20/50] | Loss: nan\n",
      "Epoch [21/50] | Loss: nan\n",
      "Epoch [22/50] | Loss: nan\n",
      "Epoch [23/50] | Loss: nan\n",
      "Epoch [24/50] | Loss: nan\n",
      "Epoch [25/50] | Loss: nan\n",
      "Epoch [26/50] | Loss: nan\n",
      "Epoch [27/50] | Loss: nan\n",
      "Epoch [28/50] | Loss: nan\n",
      "Epoch [29/50] | Loss: nan\n",
      "Epoch [30/50] | Loss: nan\n",
      "Epoch [31/50] | Loss: nan\n",
      "Epoch [32/50] | Loss: nan\n",
      "Epoch [33/50] | Loss: nan\n",
      "Epoch [34/50] | Loss: nan\n",
      "Epoch [35/50] | Loss: nan\n",
      "Epoch [36/50] | Loss: nan\n",
      "Epoch [37/50] | Loss: nan\n",
      "Epoch [38/50] | Loss: nan\n",
      "Epoch [39/50] | Loss: nan\n",
      "Epoch [40/50] | Loss: nan\n",
      "Epoch [41/50] | Loss: nan\n",
      "Epoch [42/50] | Loss: nan\n",
      "Epoch [43/50] | Loss: nan\n",
      "Epoch [44/50] | Loss: nan\n",
      "Epoch [45/50] | Loss: nan\n",
      "Epoch [46/50] | Loss: nan\n",
      "Epoch [47/50] | Loss: nan\n",
      "Epoch [48/50] | Loss: nan\n",
      "Epoch [49/50] | Loss: nan\n",
      "Epoch [50/50] | Loss: nan\n",
      "Generated data saved to 'generated_housing_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('/home/mw/.cache/kagglehub/datasets/yasserh/housing-prices-dataset/versions/1/Housing.csv')\n",
    "\n",
    "X = data.iloc[:, :-1].values\n",
    "\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "for col in categorical_columns:\n",
    "    if data[col].nunique() <= 2:\n",
    "        data[col] = LabelEncoder().fit_transform(data[col])\n",
    "    else:\n",
    "        one_hot = pd.get_dummies(data[col], prefix=col)\n",
    "        data = pd.concat([data.drop(col, axis=1), one_hot], axis=1)\n",
    "\n",
    "boolean_columns = data.select_dtypes(include='bool').columns\n",
    "data[boolean_columns] = data[boolean_columns].astype(int)\n",
    "\n",
    "numeric_columns = data.select_dtypes(include=['float64']).columns\n",
    "data[numeric_columns] = (data[numeric_columns] - data[numeric_columns].mean()) / data[numeric_columns].std()\n",
    "\n",
    "target_column = \"price\"\n",
    "features = data.drop(target_column, axis=1)\n",
    "target = data[target_column]\n",
    "\n",
    "features_tensor = torch.tensor(features.values, dtype=torch.float32)\n",
    "target_tensor = torch.tensor(target.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_train_tensor = torch.tensor(features.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(target.values, dtype=torch.float32)\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc21 = nn.Linear(512, latent_dim)\n",
    "        self.fc22 = nn.Linear(512, latent_dim)\n",
    "        self.fc3 = nn.Linear(latent_dim, 512)\n",
    "        self.fc4 = nn.Linear(512, input_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    return BCE + 0.5 * torch.sum(torch.exp(logvar) + mu.pow(2) - 1 - logvar)\n",
    "\n",
    "input_dim = features.shape[1]\n",
    "latent_dim = 32\n",
    "vae = VAE(input_dim, latent_dim)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx in range(0, len(X_train_tensor), 64):\n",
    "        data = X_train_tensor[batch_idx:batch_idx+64]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, logvar = vae(data)\n",
    "        \n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {train_loss/len(X_train_tensor):.4f}\")\n",
    "\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(64, latent_dim)\n",
    "    generated_data = vae.decode(z).cpu().numpy()\n",
    "\n",
    "generated_df = pd.DataFrame(generated_data, columns=features.columns)  # Use features.columns here\n",
    "generated_df.to_csv(\"generated_housing_data.csv\", index=False)\n",
    "\n",
    "print(\"Generated data saved to 'generated_housing_data.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sih",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
